{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import zipfile\n",
    "import cv2\n",
    "import gdown\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifier que la dataset existe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder name and download URL\n",
    "download_url = \"https://drive.google.com/uc?id=1h4ek1Gh5qYY7UfEWcnV-K0uZ-oaaxUPj\"\n",
    "\n",
    "# Check if the folder exists\n",
    "if os.path.exists('FaceMaskDataset'):\n",
    "    print(f\"The folder 'FaceMaskDataset' already exists.\")\n",
    "else:\n",
    "    # Download the zip file\n",
    "    print(\"Downloading the dataset zip file...\")\n",
    "    gdown.download(download_url, f\"FaceMaskDataset.zip\", quiet=False)\n",
    "\n",
    "    # Unzip the downloaded file without creating an additional directory\n",
    "    print(\"Unzipping the dataset...\")\n",
    "    with zipfile.ZipFile(f\"FaceMaskDataset.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "    print(\"Extraction complete.\")\n",
    "\n",
    "    # Remove the zip file after extraction\n",
    "    os.remove(f\"FaceMaskDataset.zip\")\n",
    "    print(f\"Removed 'FaceMaskDataset.zip'.\")\n",
    "\n",
    "print(\"Process completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir des variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nombre d'epochs lors de l'entrainement \n",
    "epochs=35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir les fonctions a utlisier plus tard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display images and labels with a specified title\n",
    "def display_images(images, labels, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.suptitle(title, fontsize=14)\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f'Label: {labels[i]}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#visualize fitting of model\n",
    "def check_metrics(history, figure_name):\n",
    "\n",
    "    train = history[f'{figure_name}']\n",
    "    val = history[f'val_{figure_name}']\n",
    "\n",
    "    epochs = range(1, len(train) + 1)\n",
    "    plt.plot(epochs, train, 'b', label=f'Training {figure_name}', color='orange')\n",
    "    plt.plot(epochs, val, 'b', label=f'Test {figure_name}')\n",
    "    plt.title(f'Training and Test {figure_name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(f'{figure_name}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "#visualize the confusion matrix\n",
    "def plot_confusion(model):\n",
    "    # Predicting labels using the model\n",
    "    predictions = model.predict(test_data)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)  # Convert softmax output to class labels\n",
    "\n",
    "    # Get true labels from the test data\n",
    "    true_labels = test_data.classes\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Plot confusion matrix using seaborn\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def test_epoch_time(model):\n",
    "    start_time = time.time()\n",
    "    predictions = model.predict(test_data)\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_time = end_time - start_time\n",
    "    return epoch_time\n",
    "\n",
    "def plot_training_accuracy(models):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model_name, model_dict in models.items():\n",
    "        history = model_dict['history']\n",
    "        plt.plot(history['accuracy'], label=model_name)\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Training Accuracy')\n",
    "    plt.title('Training Accuracy Improvement Through Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_validation_accuracy(models):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model_name, model_dict in models.items():\n",
    "        history = model_dict['history']\n",
    "        plt.plot(history['val_accuracy'], label=model_name)\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.title('Validation Accuracy Improvement Through Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_epoch_times(models):\n",
    "    epoch_times = []\n",
    "    model_names = []\n",
    "    for model_name, model_dict in models.items():\n",
    "        epoch_time = test_epoch_time(model_dict['model'])\n",
    "        epoch_times.append(epoch_time)\n",
    "        model_names.append(model_name)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(model_names, epoch_times, color='skyblue')\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Epoch Time (seconds)')\n",
    "    plt.title('Epoch Times for Each Model')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "def plot_number_of_parameters(models):\n",
    "    num_params = []\n",
    "    model_names = []\n",
    "    for model_name, model_dict in models.items():\n",
    "        num_param = model_dict['model'].count_params()\n",
    "        num_params.append(num_param)\n",
    "        model_names.append(model_name)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(model_names, num_params, color='salmon')\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Number of Parameters')\n",
    "    plt.title('Number of Parameters in Each Model')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrices(models):\n",
    "    for model_name, model_dict in models.items():\n",
    "        predictions = model_dict['model'].predict(test_data)\n",
    "        predicted_labels = np.argmax(predictions, axis=1)\n",
    "        true_labels = test_data.classes\n",
    "\n",
    "        cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.ylabel('True Labels')\n",
    "        plt.title(f'Confusion Matrix for {model_name}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limiting GPU memory growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des donnees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importer les donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir =r'FaceMaskDataset/test'\n",
    "test_dir =r'FaceMaskDataset/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dir =r'FaceMaskDataset/test224'\n",
    "test_dir =r'FaceMaskDataset/train224'\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = datagen.flow_from_directory(train_dir, target_size=(128, 128), batch_size=32, class_mode='categorical', shuffle=True)  \n",
    "\n",
    "test_data = datagen.flow_from_directory(test_dir, target_size=(128, 128), batch_size=32, class_mode='categorical', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualiser quelques donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of images and labels from the training dataset\n",
    "train_images, train_labels = train_data.next()\n",
    "\n",
    "# Get a batch of images and labels from the test dataset\n",
    "test_images, test_labels = test_data.next()\n",
    "\n",
    "# Display a few images from the training dataset with a label\n",
    "display_images(train_images[:8], train_labels[:8], \"8 examples from train data\")\n",
    "\n",
    "# Display a few images from the test dataset with a label\n",
    "display_images(test_images[:8], test_labels[:8], \"8 examples from test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each class in the training dataset\n",
    "train_class_counts = np.sum(train_labels, axis=0)\n",
    "\n",
    "# Count the occurrences of each class in the test dataset\n",
    "test_class_counts = np.sum(test_labels, axis=0)\n",
    "\n",
    "# Labels for the classes\n",
    "class_labels = ['face_with_mask', 'face_no_mask']\n",
    "\n",
    "# Bar plot for class proportions in the training dataset\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(class_labels, train_class_counts, color='blue', alpha=0.7, label='Training Data')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Proportions in Training Data')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Bar plot for class proportions in the test dataset\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(class_labels, test_class_counts, color='orange', alpha=0.7, label='Test Data')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Proportions in Test Data')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation des modeles (sans augmentation de données)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition des modeles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "# Modele ANN Simple\n",
    "simple_ann_model = Sequential([\n",
    "    Flatten(input_shape=(128, 128, 3)),  \n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "simple_ann_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models['simple_ann_model'] = {'model': simple_ann_model, 'history': None}\n",
    "\n",
    "# Modele ANN Complexe\n",
    "complicated_ann_model = Sequential([\n",
    "    Flatten(input_shape=(128, 128, 3)), \n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(128, activation='sigmoid'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "complicated_ann_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models['complicated_ann_model'] = {'model': complicated_ann_model, 'history': None}\n",
    "\n",
    "# Modele CNN Simple\n",
    "simple_cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "simple_cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models['simple_cnn_model'] = {'model': simple_cnn_model, 'history': None}\n",
    "\n",
    "# Modele CNN Complexe\n",
    "complicated_cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "complicated_cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models['complicated_cnn_model'] = {'model': complicated_cnn_model, 'history': None}\n",
    "\n",
    "# Transfer Learning using VGG16\n",
    "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "transfer_vgg_model = Sequential([\n",
    "    vgg_base,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "transfer_vgg_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models['transfer_vgg_model'] = {'model': transfer_vgg_model, 'history': None}\n",
    "\n",
    "# Transfer Learning using VGG16 with unfrozen layers\n",
    "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "transfer_vgg_model_unfrozen = Sequential([\n",
    "    vgg_base,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "for layer in transfer_vgg_model_unfrozen.layers[0].layers[-5:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "transfer_vgg_model_unfrozen.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models['transfer_vgg_model_unfrozen'] = {'model': transfer_vgg_model_unfrozen, 'history': None}\n",
    "\n",
    "# Transfer Learning using ResNet50\n",
    "resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "transfer_resnet_model = Sequential([\n",
    "    resnet_base,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "transfer_resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models['transfer_resnet_model'] = {'model': transfer_resnet_model, 'history': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement des modeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the directory exists, if not, create it\n",
    "save_dir = 'saved_models/without_data_augmentation'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Loop through models\n",
    "for model_name, model_info in models.items():\n",
    "    model = model_info['model']\n",
    "    model_history = model_info['history']\n",
    "\n",
    "    # Check if the model and history files exist\n",
    "    model_filename = os.path.join(save_dir, f'{model_name}_model.h5')\n",
    "    history_filename = os.path.join(save_dir, f'{model_name}_history.pkl')\n",
    "\n",
    "    if os.path.exists(model_filename) and os.path.exists(history_filename):\n",
    "        # Load existing model and history\n",
    "        loaded_model = load_model(model_filename)\n",
    "        with open(history_filename, 'rb') as history_file:\n",
    "            loaded_history = pickle.load(history_file)\n",
    "\n",
    "        # Update the model and history in the dictionary\n",
    "        models[model_name]['model'] = loaded_model\n",
    "        models[model_name]['history'] = loaded_history\n",
    "\n",
    "        print(f\"Loaded existing model and history for {model_name}\")\n",
    "    else:\n",
    "        print(f\"Training model {model_name}\")\n",
    "         # Define ModelCheckpoint callback to save the best model during training\n",
    "        checkpoint = ModelCheckpoint(f'saved_models/without_data_augmentation/{model_name}.h5', \n",
    "                                 monitor='val_accuracy', \n",
    "                                 save_best_only=True, \n",
    "                                 mode='max', \n",
    "                                 verbose=1)\n",
    "\n",
    "        history = model.fit(train_data, epochs=epochs, \n",
    "                        validation_data=test_data,\n",
    "                        callbacks=[checkpoint])\n",
    "\n",
    "\n",
    "        # Save the history\n",
    "        with open(history_filename, 'wb') as history_file:\n",
    "            pickle.dump(history.history, history_file)\n",
    "\n",
    "        # Update the model and history in the dictionary\n",
    "        models[model_name]['history'] = history.history\n",
    "\n",
    "        print(f\"Trained and saved model and history for {model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalutation Individuelle des modeles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'simple_ann_model'\n",
    "history = models[chosen_model_name]['history']\n",
    "model = models[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_metrics(history, 'loss')\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_time(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Complexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'complicated_ann_model'\n",
    "history = models[chosen_model_name]['history']\n",
    "model = models[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_metrics(history, 'loss')\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_time(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'simple_cnn_model'\n",
    "history = models[chosen_model_name]['history']\n",
    "model = models[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_metrics(history, 'loss')\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_time(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Complexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'complicated_cnn_model'\n",
    "history = models[chosen_model_name]['history']\n",
    "model = models[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_metrics(history, 'loss')\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_time(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning avec vgg (frozen base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'transfer_vgg_model'\n",
    "history = models[chosen_model_name]['history']\n",
    "model = models[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_metrics(history, 'loss')\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_time(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning avec vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'transfer_vgg_model_unfrozen'\n",
    "history = models[chosen_model_name]['history']\n",
    "model = models[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_metrics(history, 'loss')\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_time(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning avec resnet (frozen base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'transfer_resnet_model'\n",
    "history = models[chosen_model_name]['history']\n",
    "model = models[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_metrics(history, 'loss')\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_time(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des modeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_accuracy(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_validation_accuracy(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_times(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_number_of_parameters(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrices(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation des modeles (avec aumentation de données)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition des modeles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_augmented = {}\n",
    "\n",
    "# Modele ANN Simple\n",
    "simple_ann_model = Sequential([\n",
    "    Flatten(input_shape=(128, 128, 3)),  \n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "simple_ann_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_augmented['simple_ann_model'] = {'model': simple_ann_model, 'history': None}\n",
    "\n",
    "# Modele ANN Complexe\n",
    "complicated_ann_model = Sequential([\n",
    "    Flatten(input_shape=(128, 128, 3)), \n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(128, activation='sigmoid'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "complicated_ann_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_augmented['complicated_ann_model'] = {'model': complicated_ann_model, 'history': None}\n",
    "\n",
    "# Modele CNN Simple\n",
    "simple_cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "simple_cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_augmented['simple_cnn_model'] = {'model': simple_cnn_model, 'history': None}\n",
    "\n",
    "# Modele CNN Complexe\n",
    "complicated_cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "complicated_cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_augmented['complicated_cnn_model'] = {'model': complicated_cnn_model, 'history': None}\n",
    "\n",
    "# Transfer Learning using VGG16\n",
    "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "transfer_vgg_model = Sequential([\n",
    "    vgg_base,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "transfer_vgg_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_augmented['transfer_vgg_model'] = {'model': transfer_vgg_model, 'history': None}\n",
    "\n",
    "# Transfer Learning using VGG16 with unfrozen layers\n",
    "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "transfer_vgg_model_unfrozen = Sequential([\n",
    "    vgg_base,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "for layer in transfer_vgg_model_unfrozen.layers[0].layers[-5:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "transfer_vgg_model_unfrozen.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_augmented['transfer_vgg_model_unfrozen'] = {'model': transfer_vgg_model_unfrozen, 'history': None}\n",
    "\n",
    "# Transfer Learning using ResNet50\n",
    "resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "transfer_resnet_model = Sequential([\n",
    "    resnet_base,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "transfer_resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "models_augmented['transfer_resnet_model'] = {'model': transfer_resnet_model, 'history': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement des modeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator instance with desired augmentations\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1]\n",
    "    rotation_range=20,  # Rotate images randomly by up to 20 degrees\n",
    "    width_shift_range=0.2,  # Shift images horizontally by up to 20% of the width\n",
    "    height_shift_range=0.2,  # Shift images vertically by up to 20% of the height\n",
    "    shear_range=0.2,  # Shear transformations\n",
    "    zoom_range=0.2,  # Zoom inside images\n",
    "    horizontal_flip=True,  # Flip images horizontally\n",
    "    fill_mode='nearest'  # Fill in newly created pixels after rotation or shift\n",
    ")\n",
    "\n",
    "# Load your dataset using flow_from_directory or flow_from_dataframe\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128, 128),  # Specify target size of the images\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'  # Choose 'binary' for binary classification\n",
    ")\n",
    "\n",
    "\n",
    "# Check if the directory exists, if not, create it\n",
    "save_dir = 'saved_models/with_data_augmentation'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Loop through models\n",
    "for model_name, model_info in models_augmented.items():\n",
    "    model = model_info['model']\n",
    "    model_history = model_info['history']\n",
    "\n",
    "    # Check if the model and history files exist\n",
    "    model_filename = os.path.join(save_dir, f'{model_name}_model.h5')\n",
    "    history_filename = os.path.join(save_dir, f'{model_name}_history.pkl')\n",
    "\n",
    "    if os.path.exists(model_filename) and os.path.exists(history_filename):\n",
    "        # Load existing model and history\n",
    "        loaded_model = load_model(model_filename)\n",
    "        with open(history_filename, 'rb') as history_file:\n",
    "            loaded_history = pickle.load(history_file)\n",
    "\n",
    "        # Update the model and history in the dictionary\n",
    "        models_augmented[model_name]['model'] = loaded_model\n",
    "        models_augmented[model_name]['history'] = loaded_history\n",
    "\n",
    "        print(f\"Loaded existing model and history for {model_name}\")\n",
    "    else:\n",
    "        print(f\"Training model {model_name}\")\n",
    "         # Define ModelCheckpoint callback to save the best model during training\n",
    "        checkpoint = ModelCheckpoint(f'saved_models/with_data_augmentation/{model_name}.h5', \n",
    "                                    monitor='val_accuracy', \n",
    "                                    save_best_only=True, \n",
    "                                    mode='max', \n",
    "                                    verbose=1)\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(train_data, epochs=epochs, \n",
    "                            validation_data=test_data,\n",
    "                            callbacks=[checkpoint])\n",
    "\n",
    "\n",
    "        # Save the history\n",
    "        with open(history_filename, 'wb') as history_file:\n",
    "            pickle.dump(history.history, history_file)\n",
    "\n",
    "        # Update the model and history in the dictionary\n",
    "        models_augmented[model_name]['history'] = history.history\n",
    "\n",
    "        print(f\"Trained and saved model and history for {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalutation Individuelle des modeles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'simple_ann_model'\n",
    "history = models_augmented[chosen_model_name]['history']\n",
    "model = models_augmented[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_metrics(history, 'loss')\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_time(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Complexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'complicated_ann_model'\n",
    "history = models_augmented[chosen_model_name]['history']\n",
    "model = models_augmented[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_metrics(history, 'loss')\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_time(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'simple_cnn_model'\n",
    "history = models_augmented[chosen_model_name]['history']\n",
    "model = models_augmented[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_metrics(history, 'loss')\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_time(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Complexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'complicated_cnn_model'\n",
    "history = models_augmented[chosen_model_name]['history']\n",
    "model = models_augmented[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_metrics(history, 'loss')\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_time(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning avec vgg (frozen base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'transfer_vgg_model'\n",
    "history = models_augmented[chosen_model_name]['history']\n",
    "model = models_augmented[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_metrics(history, 'loss')\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_time(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning avec vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'transfer_vgg_model_unfrozen'\n",
    "history = models_augmented[chosen_model_name]['history']\n",
    "model = models_augmented[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_metrics(history, 'loss')\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_time(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning avec resnet (frozen base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'transfer_resnet_model'\n",
    "history = models_augmented[chosen_model_name]['history']\n",
    "model = models_augmented[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_metrics(history, 'loss')\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_time(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des modeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_accuracy(models_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_validation_accuracy(models_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_times(models_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_number_of_parameters(models_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrices(models_augmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation des modeles avec et sans transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Individuelle des modeles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'transfer_resnet_model'\n",
    "\n",
    "history_augmented = models_augmented[chosen_model_name]['history']\n",
    "model_augmented = models_augmented[chosen_model_name]['model']\n",
    "\n",
    "history = models[chosen_model_name]['history']\n",
    "model = models[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "check_metrics(history_augmented, 'loss')\n",
    "print(\"pour le cas sans augmentation de données\")\n",
    "check_metrics(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "check_metrics(history_augmented, 'accuracy')\n",
    "print(\"pour le cas sans augmentation de données\")\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "plot_confusion(model_augmented)\n",
    "print(\"pour le sans augmentation de données\")\n",
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Complexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'transfer_resnet_model'\n",
    "\n",
    "history_augmented = models_augmented[chosen_model_name]['history']\n",
    "model_augmented = models_augmented[chosen_model_name]['model']\n",
    "\n",
    "history = models[chosen_model_name]['history']\n",
    "model = models[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "check_metrics(history_augmented, 'loss')\n",
    "print(\"pour le cas sans augmentation de données\")\n",
    "check_metrics(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "check_metrics(history_augmented, 'accuracy')\n",
    "print(\"pour le cas sans augmentation de données\")\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "plot_confusion(model_augmented)\n",
    "print(\"pour le sans augmentation de données\")\n",
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'transfer_resnet_model'\n",
    "\n",
    "history_augmented = models_augmented[chosen_model_name]['history']\n",
    "model_augmented = models_augmented[chosen_model_name]['model']\n",
    "\n",
    "history = models[chosen_model_name]['history']\n",
    "model = models[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "check_metrics(history_augmented, 'loss')\n",
    "print(\"pour le cas sans augmentation de données\")\n",
    "check_metrics(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "check_metrics(history_augmented, 'accuracy')\n",
    "print(\"pour le cas sans augmentation de données\")\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "plot_confusion(model_augmented)\n",
    "print(\"pour le sans augmentation de données\")\n",
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Complexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'transfer_resnet_model'\n",
    "\n",
    "history_augmented = models_augmented[chosen_model_name]['history']\n",
    "model_augmented = models_augmented[chosen_model_name]['model']\n",
    "\n",
    "history = models[chosen_model_name]['history']\n",
    "model = models[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "check_metrics(history_augmented, 'loss')\n",
    "print(\"pour le cas sans augmentation de données\")\n",
    "check_metrics(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "check_metrics(history_augmented, 'accuracy')\n",
    "print(\"pour le cas sans augmentation de données\")\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "plot_confusion(model_augmented)\n",
    "print(\"pour le sans augmentation de données\")\n",
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Transfer learning avec vgg (frozen base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'transfer_resnet_model'\n",
    "\n",
    "history_augmented = models_augmented[chosen_model_name]['history']\n",
    "model_augmented = models_augmented[chosen_model_name]['model']\n",
    "\n",
    "history = models[chosen_model_name]['history']\n",
    "model = models[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "check_metrics(history_augmented, 'loss')\n",
    "print(\"pour le cas sans augmentation de données\")\n",
    "check_metrics(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "check_metrics(history_augmented, 'accuracy')\n",
    "print(\"pour le cas sans augmentation de données\")\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "plot_confusion(model_augmented)\n",
    "print(\"pour le sans augmentation de données\")\n",
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning avec vgg (frozen base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'transfer_resnet_model'\n",
    "\n",
    "history_augmented = models_augmented[chosen_model_name]['history']\n",
    "model_augmented = models_augmented[chosen_model_name]['model']\n",
    "\n",
    "history = models[chosen_model_name]['history']\n",
    "model = models[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "check_metrics(history_augmented, 'loss')\n",
    "print(\"pour le cas sans augmentation de données\")\n",
    "check_metrics(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "check_metrics(history_augmented, 'accuracy')\n",
    "print(\"pour le cas sans augmentation de données\")\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "plot_confusion(model_augmented)\n",
    "print(\"pour le sans augmentation de données\")\n",
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning avec resnet (frozen base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_name = 'transfer_resnet_model'\n",
    "\n",
    "history_augmented = models_augmented[chosen_model_name]['history']\n",
    "model_augmented = models_augmented[chosen_model_name]['model']\n",
    "\n",
    "history = models[chosen_model_name]['history']\n",
    "model = models[chosen_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "check_metrics(history_augmented, 'loss')\n",
    "print(\"pour le cas sans augmentation de données\")\n",
    "check_metrics(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "check_metrics(history_augmented, 'accuracy')\n",
    "print(\"pour le cas sans augmentation de données\")\n",
    "check_metrics(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "plot_confusion(model_augmented)\n",
    "print(\"pour le sans augmentation de données\")\n",
    "plot_confusion(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des modeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le cas avec augmentation de données\")\n",
    "plot_training_accuracy(models_augmented)\n",
    "print(\"pour le sans augmentation de données\")\n",
    "plot_training_accuracy(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pour le sans augmentation de données\")\n",
    "plot_validation_accuracy(models_augmented)\n",
    "print(\"pour le sans augmentation de données\")\n",
    "plot_validation_accuracy(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyautogui\n",
    "import time\n",
    "\n",
    "# Simulate Ctrl + S (save) keystrokes\n",
    "pyautogui.hotkey('ctrl', 's')\n",
    "time.sleep(20)  # Allow time for the save operation to complete\n",
    "\n",
    "# Shut down the computer immediately\n",
    "os.system(\"shutdown /s /t 1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained face detection and mask detection models\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "mask_model = load_model(r'saved_models/without_transfer_learning/simple_ann_model.h5')\n",
    "\n",
    "# Function to detect face and predict mask\n",
    "def detect_mask(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_roi = frame[y:y+h, x:x+w]\n",
    "        face_roi = cv2.resize(face_roi, (128, 128))  # Resize to match model input size\n",
    "        face_roi = cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "\n",
    "        face_roi = face_roi.astype('float') / 255.0\n",
    "        face_roi = np.expand_dims(face_roi, axis=0)  # Add batch dimension\n",
    "\n",
    "        mask_result = mask_model.predict(face_roi)\n",
    "        if mask_result[0][0] > mask_result[0][1]:  # Assuming [mask, no_mask] classes\n",
    "            label = \"Mask\"\n",
    "            color = (0, 255, 0)  # Green for wearing a mask\n",
    "        else:\n",
    "            label = \"No Mask\"\n",
    "            color = (0, 0, 255)  # Red for not wearing a mask\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "        cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)  # Use 0 for the default webcam\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = detect_mask(frame)\n",
    "    cv2.imshow('Mask Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
